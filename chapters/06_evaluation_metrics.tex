\fancychapter{Evaluation Metrics}


\section{Clustering Tweets with Self-Organizing Maps}
\label{ch:clustering_tweets}

\subsection{Twitter Dataset}
\label{subsec:twitter_dataset}

Each tweet is comprised of multiple parameters. Figure~\ref{fig:json_tweet} shows how a tweet is represented in \ac{JSON} format. Inside the tweet there is also information about the user whom created the tweet, shown in Figure~\ref{fig:json_tweet_user} and entities shown in Figure~\ref{fig:tweet_enteties}.

As can be seen in Figure~\ref{fig:json_tweet_user} no information about the social relations of the user which emitted the tweet are present. Therefor in order to retrieve the social network in which a user is contained, it will be necessary to connect to the Twitter API. Crawling twitter is discussed in further depth in Chapter~\ref{chap:crawling_twitter}.  

\input{./images/json.tex}

In order to better understand the dataset at hand, all the \ac{JSON} files where converted into \ac{CSV}in a way to reduce the size of the dataset. While tweets where being converted, \ac{URL} where removed --- since most of them where minified in order to fit in less that 140 characters, without translating the minified URL, not a lot of information can be gathered. Also, all tweets that where not identified as being in English where also removed. The tweet shown in \ac{JSON} format in Figure~\ref{fig:json_tweet} is converted to \ac{CSV} in Figure~\ref{fig:csv_tweet}.

\input{./images/tweet_csv.tex}
{\color{red} Add table with dataset characteristics }
\input{./tables/inesc_dataset.tex}

\subsection{SOM training}
\label{sub:clustering_tweets_with_soms}
{\color{red} Refer dataset info on }
{\color{red} Describe naive approach to SOM training in R }
{\color{red} Describe amount of weird words }

\subsection{Reducing SOM vector size}
\label{sub:reducing_som_vector_size}

\subsubsection{Identify Tweets language}
\label{ssub:identify_tweets_lang}
Identifying tweets that where not in the English language was done through the usage of Ruby library called whatlanguage~\footnote{https://github.com/peterc/whatlanguage}, which tries to identify one language through Bloom Filters. Inside the tweet there is a field which identifies the user language, we found that x is not acurate. Removing tweets that weren't in the english language reduced the amount of different words in x and therefor will reduce the dimensional size of the \ac{SOM}.

\subsubsection{Text Manipulation for VSM reduction}
\label{ssub:Text Manipulation for SVM reduction}
{\color{red} all the text techniques used }
{\color{red} show amount of words reduction with the introduction of a new technique and the amount of time that it takes to be applied }

Work done on the INESC twitter dataset with SOMs.
SOM implementations used, what where their strong points and weaknesses

\subsubsection{Clustering with Word Selection }
\label{ssub:Word Selection for Clustering}
{\color{red} Results of SOMs using selected words based on occurrence after applying SVM reduction }
{\color{red} Results where pretty bad }

\subsection{Clustering with NLP selected words}
\label{sub:clustering_with_nlp_selected_words}
{\color{red} results of som using arktweet NLP }
{\color{red} types of tags selected }
{\color{red} show tweets that had no representation }
{\color{red} review clusters and results }
 
\section{Conclusions}
{\color{red} Only these methods are not enough to cluster tweets }

% Ensure that the next chapter starts in a odd page
\cleardoublepage
 
%%%%%% REMOVED STUFF
%\subsection{Topology Preservation} 
%\label{sub:topology_preservation}
%The Self-Organizing Map performs a mapping from the n-dimensional input space into the two dimensional output space and where resides one the most fascinating characteristics, which is that the output map tries to preserve the topology from the input space. This grants the SOM algorithm a way to visualize high-dimensional data that other neural networks or clustering algorithms don't have. Even though this is true, sometimes during training it is not possible to preserve the topology of the network.
%Thus topology preservation can be measured through the Topographic error~\citet{Kiviluoto1996} which is the proportion of all data vectors for which first and second BMUs \footnote{unit that is closest to the winning neuron. BMU Best fitting unit } are not adjacent units.
%In this project the Topographic Error will be calculated for all SOM implementations and VSM usages in order to understand if the representation of the SOM output space is well defined.

 %\begin{itemize}
  %\item show UMatrixes and multiple steps map trainning of the SOM library trainnig
  %\item show metrics for the crawller, tweets per second, users persecond, size of the dump a long the time.
  %\item compare my som library with other som libraries: training velocity with diferent parameters, map after trainned.
  %\item Compare Homophilic-SOM results with non homophilic: UMatrixes, cluster results, Quantization error, jacknife. 
%\end{itemize}
%%\section{Evaluation Metrics} 
%%\label{sec:evaluation_metrics}
%Evaluation of the topic detection on Tweets will be made in two distinct ways. The first way will focus on  binary classification using the precision and recall metrics, and will be described in Subsection~\ref{sub:testing_for_precision_and_recall}. The second way will focus on statistically testing the SOM learning process and the computed trained network. This testing process will be described in Subsection~\ref{sub:cluster_quality_testing}. 

%\section{Testing for Precision and Recall} 
%\label{sec:testing_for_precision_and_recall}
%Precision and Recall are both ways to measure the rate of right guesses made by the trained SOM network, and are defined in the following way:
%\begin{itemize}
  %\item \textbf{Precision:} Fraction of retrieved instances that where relevant 
    %\input{./equations/precision.tex}
  %\item \textbf{Recall:} Fraction of relevant instances that where retrieved
    %\input{./equations/recall.tex}
%\end{itemize}
 
%In order to calculate Precision and Recall we need to have the \emph{relevant documents} and the \emph{retrieved documents}. The \emph{relevant documents} are rather hard to determine because they need to be categorized by humans, which is an expensive task.
