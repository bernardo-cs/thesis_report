% Self Organinzing Map algorithm in latex, needs package algorithm2e
\begin{figure}[h]
  \begin{algorithm}[H]
    \label{alg:som}
    \DontPrintSemicolon
    \KwData{Input patterns $X = \{  \overrightarrow{x_1}$,\dots,$\overrightarrow{x_N}$ \}, number of iterations $t_{\textrm{$max$}}$,  neighborhood function $\sigma(t)$, learning rate  $\epsilon(t)$ }
    \KwResult{Trainned map and clustered input patterns}
    Randomly initialize neurons, $w_i \in \mathbb{R}^{D}, \forall i $ \;
    \For{ $t = 1 \; to \; t_{\textrm{$max$}}$ }{
      Randomly draw an input pattern, $ \overrightarrow{x_d} $  \;
      \nl\label{som:one}$p =  \arg{ min_i \{ \|  \overrightarrow{x_d} - \overrightarrow{w_i} \|  \}}  $  \;
      \nl\label{som:two}$\overrightarrow{w_i} = \overrightarrow{w_i} + \epsilon(t) \cdot h_{ip}(t) \cdot ( \overrightarrow{x_d} - \overrightarrow{w_i} ),  \forall{i}$ \;
      \nl\label{som:three}$\sigma(t) = \sigma_0( \sigma_f / \sigma_0 )^{t/t_{max}}$  \;
      \nl\label{som:four}$\epsilon(t) = \epsilon_0( \epsilon_f / \epsilon_0 )^{t/t_{max}}$ \;  
      \nl\label{som:fifth}$ t \leftarrow t + 1$}
      \caption{Self-Organizing Map \cite[]{Kohonen1990} }
  \end{algorithm}
\end{figure}

The learning phase is characterized by the Agorithm~\ref{alg:som}, which works the following way:
\begin{itemize}
  \item On line~\ref{som:one} neuron closer to the input pattern is selected. The euclidian distance (Eq.~\ref{eq:eucl_dist}) is generally used.
    \input{./equations/eucl_dist.tex}
  \item On line~\ref{som:two} the winning neuron $(p)$ previously selected on line~\ref{som:one} is updated, in order to better represent the inputt pattern. This process is represented on Figure~\ref{fig:4_wining_neuron_converge}. Also, all other neurons inside a specific radius will also be updated, this process is described in Figure~\ref{fig:5_neighbours_converge}. Each neuron is updated with a different rate of influence determined by how far away it is from the winning neuron, which is defined by the neighborhood influence function $h_ip(t)$ the Gaussian (Eq.~\ref{eq:gaussian}) is often used. 
    \input{./equations/gaussian.tex}
  \item On line~\ref{som:three} the size of the radius will be updated.
  \item On line~\ref{som:four} the learning rate is updated.
  \item On line~\ref{som:fifth} the number of iterations is incremented.
  \item In order for the algorithm to converge, the learning rate and the radius of the neighbourhood need to decrease at a given rate. Generally exponential decay is used.
\end{itemize}
 
